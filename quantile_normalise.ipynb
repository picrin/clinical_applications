{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separately quantile normalise blood and muscle data. \n",
    "\n",
    "This step uses ~32 GB of RAM. We've used AWS m5.4xlarge with 64 GB of RAM to run this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import numpy\n",
    "import math\n",
    "import time\n",
    "\n",
    "def sortDist(d):\n",
    "    sortedd = [(v, i) for i, v in enumerate(d)]\n",
    "    sortedd.sort()\n",
    "    return sortedd\n",
    "\n",
    "def avgDist(args):\n",
    "    toReturn = []\n",
    "    for tuplas in zip(*args):\n",
    "        toAdd = float(0)\n",
    "        for v, _ in tuplas:\n",
    "            toAdd += v\n",
    "        toAdd /= len(tuplas)\n",
    "        toReturn.append(toAdd)\n",
    "    return toReturn\n",
    "\n",
    "def quantileNormalise(args):\n",
    "    args = [sortDist(d) for d in args]\n",
    "    avgd = avgDist(args)\n",
    "    toReturn = []\n",
    "    for dist in args:\n",
    "        normDist = [(i, a) for a, (v, i) in zip(avgd, dist)]\n",
    "        normDist.sort()\n",
    "        normDist = [j for (i, j) in normDist]\n",
    "        yield(normDist)\n",
    "\n",
    "d1 = [10, 9, 11, 23]\n",
    "d2 = [4, 6, 7, 5]\n",
    "\n",
    "assert(list(quantileNormalise([d1, d2])) == [[7.5, 6.5, 8.5, 15], [6.5, 8.5, 15, 7.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metadata():\n",
    "    metadata = {}\n",
    "    with open(\"metadata.txt\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            line = line.strip().split()\n",
    "            if i == 0:\n",
    "                names = line[1:]\n",
    "            else:\n",
    "                values = line[1:]\n",
    "                metadata[line[0]] = {k: v for k, v in zip(names, values)}\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = load_metadata()\n",
    "blood_CELs = [metadata[i][\"blood_cel\"] for i in metadata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "muscle_CELs = [metadata[i][\"muscle_cel\"] for i in metadata if metadata[i][\"muscle_cel\"] != \"refused_biopsy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_intensity_data(paths):\n",
    "    intensities = []\n",
    "    for path in paths:\n",
    "        with open(path) as f:\n",
    "            intensity = numpy.loadtxt(f)\n",
    "            intensities.append(intensity)\n",
    "    return intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_qn(filenames):\n",
    "    prefix = \"intensities\"\n",
    "    qn_result = \"qn\"\n",
    "    intensities = [os.path.join(prefix, i + \".txt\") for i in filenames]\n",
    "    data = load_intensity_data(intensities)\n",
    "    rows, columns = data[0].shape\n",
    "    data = [i.reshape(rows*columns) for i in data]\n",
    "    data = [numpy.vectorize(math.log)(i) for i in data]\n",
    "    try:\n",
    "        os.mkdir(qn_result)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    start = time.time()\n",
    "    for i, result in enumerate(quantileNormalise(data)):\n",
    "        with open(os.path.join(qn_result, os.path.split(intensities[i])[1]), \"w\") as f:\n",
    "            result = numpy.array(result).reshape(rows, columns)\n",
    "            for row in result:\n",
    "                    for element in row:\n",
    "                        print(str(element), end=\" \", file=f)\n",
    "                    print(file=f)\n",
    "    stop = time.time()\n",
    "    print(stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913.9415073394775\n"
     ]
    }
   ],
   "source": [
    "dump_qn(muscle_CELs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1228.7086071968079\n"
     ]
    }
   ],
   "source": [
    "dump_qn(blood_CELs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blood_CELs) + len(muscle_CELs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
